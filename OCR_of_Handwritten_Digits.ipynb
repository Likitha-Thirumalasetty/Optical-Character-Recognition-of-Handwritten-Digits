{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPPQpBePNf13PjSPPxG71ND",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Likitha-Thirumalasetty/Optical-Character-Recognition-of-Handwritten-Digits/blob/main/OCR_of_Handwritten_Digits.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### OCR (Optical Character Recognition)  \n",
        "OCR is a technology that converts text from images, handwritten notes, or printed documents into machine-readable text. It uses machine learning and deep learning algorithms, like convolutional neural networks (CNNs), to recognize characters and patterns. Applications include digitizing books, automating data entry, and recognizing handwritten text in real-world scenarios.\n",
        "\n",
        "### MNIST Dataset  \n",
        "The MNIST dataset is a widely-used benchmark in machine learning, containing 70,000 grayscale images of handwritten digits (0–9), with 60,000 for training and 10,000 for testing. Each 28x28 pixel image is ideal for evaluating models in image classification and serves as a foundational dataset for beginners in deep learning."
      ],
      "metadata": {
        "id": "ETjNHRaSLCfz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# loading the libraries\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.metrics import classification_report"
      ],
      "metadata": {
        "id": "wr6DtljTMBzj"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load MNIST dataset\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()"
      ],
      "metadata": {
        "id": "ZAlkOKFlFRyQ"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data preprocessing"
      ],
      "metadata": {
        "id": "XNChObuTMUFk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalize the data\n",
        "x_train = x_train.astype('float32') / 255.0\n",
        "x_test = x_test.astype('float32') / 255.0\n",
        "\n",
        "# Reshape data to include channel dimension\n",
        "x_train = x_train.reshape(-1, 28, 28, 1)\n",
        "x_test = x_test.reshape(-1, 28, 28, 1)\n",
        "\n",
        "# One-hot encode the labels\n",
        "y_train = to_categorical(y_train, num_classes=10)\n",
        "y_test = to_categorical(y_test, num_classes=10)"
      ],
      "metadata": {
        "id": "wxUDkxjbMM0r"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Building the model"
      ],
      "metadata": {
        "id": "IVT7iTZsMcKo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Build CNN model\n",
        "model = Sequential([\n",
        "    Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
        "    MaxPooling2D(pool_size=(2, 2)),\n",
        "    Dropout(0.25),\n",
        "\n",
        "    Conv2D(64, kernel_size=(3, 3), activation='relu'),\n",
        "    MaxPooling2D(pool_size=(2, 2)),\n",
        "    Dropout(0.25),\n",
        "\n",
        "    Flatten(),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dropout(0.5),\n",
        "    Dense(10, activation='softmax')  # 10 classes for digits 0-9\n",
        "])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1RhCtphmMdg8",
        "outputId": "64252ee3-207f-40d9-b27e-da5564cdaa44"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Compiling the model"
      ],
      "metadata": {
        "id": "NKPxHfS_MiMq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "nkUDRQOUMjjJ"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training the model"
      ],
      "metadata": {
        "id": "uwHMwOSnMp2F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "model.fit(x_train, y_train, validation_data=(x_test, y_test), epochs=10, batch_size=128)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3zUNWKwSMozh",
        "outputId": "07e1f174-5f7f-42e6-babd-ac33a77a71d8"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 118ms/step - accuracy: 0.7721 - loss: 0.7071 - val_accuracy: 0.9759 - val_loss: 0.0796\n",
            "Epoch 2/10\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 117ms/step - accuracy: 0.9587 - loss: 0.1367 - val_accuracy: 0.9842 - val_loss: 0.0466\n",
            "Epoch 3/10\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 119ms/step - accuracy: 0.9716 - loss: 0.0983 - val_accuracy: 0.9877 - val_loss: 0.0365\n",
            "Epoch 4/10\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 117ms/step - accuracy: 0.9756 - loss: 0.0802 - val_accuracy: 0.9876 - val_loss: 0.0345\n",
            "Epoch 5/10\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 117ms/step - accuracy: 0.9784 - loss: 0.0710 - val_accuracy: 0.9899 - val_loss: 0.0297\n",
            "Epoch 6/10\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 117ms/step - accuracy: 0.9799 - loss: 0.0661 - val_accuracy: 0.9903 - val_loss: 0.0306\n",
            "Epoch 7/10\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 121ms/step - accuracy: 0.9826 - loss: 0.0562 - val_accuracy: 0.9913 - val_loss: 0.0262\n",
            "Epoch 8/10\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 117ms/step - accuracy: 0.9853 - loss: 0.0505 - val_accuracy: 0.9913 - val_loss: 0.0257\n",
            "Epoch 9/10\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 117ms/step - accuracy: 0.9852 - loss: 0.0496 - val_accuracy: 0.9915 - val_loss: 0.0233\n",
            "Epoch 10/10\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 115ms/step - accuracy: 0.9853 - loss: 0.0462 - val_accuracy: 0.9920 - val_loss: 0.0231\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7c82f4183040>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluating the model"
      ],
      "metadata": {
        "id": "q6UUZzsoMqAa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model\n",
        "loss, accuracy = model.evaluate(x_test, y_test)\n",
        "print(f\"Test Accuracy: {accuracy:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zh9IRV9AMo5Z",
        "outputId": "6f1f2dad-d36e-4526-adaa-45cb55e62f5d"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.9906 - loss: 0.0275\n",
            "Test Accuracy: 0.99\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Prediction made"
      ],
      "metadata": {
        "id": "1A9AqwouO3J5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict on the test set\n",
        "y_pred = model.predict(x_test)\n",
        "y_pred_classes = y_pred.argmax(axis=1)\n",
        "y_true = y_test.argmax(axis=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_D289A4zO2XD",
        "outputId": "6c50d23c-0ff1-4ea2-d3ac-de2d3ef16f22"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Test Report"
      ],
      "metadata": {
        "id": "gacn_pLwO8p5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Classification report\n",
        "print(classification_report(y_true, y_pred_classes))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IvWX_cPhO95_",
        "outputId": "f6d2da14-49b1-457e-b0bb-8342f3544d74"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.99      0.99       980\n",
            "           1       1.00      1.00      1.00      1135\n",
            "           2       0.99      0.99      0.99      1032\n",
            "           3       0.99      0.99      0.99      1010\n",
            "           4       1.00      0.99      0.99       982\n",
            "           5       0.99      0.99      0.99       892\n",
            "           6       0.99      0.99      0.99       958\n",
            "           7       0.99      0.99      0.99      1028\n",
            "           8       1.00      0.99      0.99       974\n",
            "           9       0.99      0.99      0.99      1009\n",
            "\n",
            "    accuracy                           0.99     10000\n",
            "   macro avg       0.99      0.99      0.99     10000\n",
            "weighted avg       0.99      0.99      0.99     10000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Testing the model on a random image"
      ],
      "metadata": {
        "id": "mT4mWBWVO_gB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "# Load the trained model\n",
        "model = load_model('handwritten_digit_recognition.h5')\n",
        "\n",
        "# Pick a random image from the test dataset\n",
        "random_index = np.random.randint(0, x_test.shape[0])\n",
        "random_image = x_test[random_index]\n",
        "true_label = y_test[random_index].argmax()\n",
        "\n",
        "# Display the image\n",
        "plt.imshow(random_image.reshape(28, 28), cmap='gray')\n",
        "plt.title(f\"True Label: {true_label}\")\n",
        "plt.axis('off')\n",
        "plt.show()\n",
        "\n",
        "# Preprocess the image for prediction\n",
        "random_image = random_image.reshape(1, 28, 28, 1)  # Reshape to match input dimensions\n",
        "\n",
        "# Predict using the model\n",
        "prediction = model.predict(random_image)\n",
        "predicted_label = np.argmax(prediction)\n",
        "\n",
        "# Display the prediction\n",
        "print(f\"Predicted Label: {predicted_label}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 483
        },
        "id": "3LVncxOyKsss",
        "outputId": "755c3773-274b-4970-be1b-1b2c47b0d342"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step\n",
            "Predicted Label: 6\n"
          ]
        }
      ]
    }
  ]
}